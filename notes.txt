Стюарды первого класса обслуживали всего несколько кают, тогда как на одного стюарда второго и третьего классов приходилось большое количество пассажиров.
Стюарды в первом классе помогали пассажирам одеваться и проходить на палубу, успокаивали их, объясняя, что посадка в шлюпки женщин и детей будет производиться только в качестве меры предосторожности. 
Особое внимание уделялось одиноким женщинам и женщинам с детьми. Во втором и третьем классе стюарды просто распахивали двери и приказывали надеть спасательные жилеты под надуманным предлогом, либо без объяснения причин.
 Пассажиры третьего класса были оставлены фактически на произвол судьбы. 
Им лишь сообщили о необходимости подняться наверх, и те долго блуждали по длинным коридорам нижних палуб, пытаясь найти выход

3 class 
Четверо из пяти спасшихся людей являлись пассажирами первого и второго классов. 
Ближе всех к шлюпочной палубе были пассажиры первого класса, каюты которых располагались преимущественно на верхних палубах, поэтому среди них велика доля спасённых (62 %). 
Большая часть пассажиров третьего класса не смогла выбраться из лабиринта коридоров нижних палуб. 
Они были отделены от первого и второго классов воротами, находившимися в разных частях судна, многие из которых оказались закрыты[165]. 
В некоторых местах экипаж «Титаника» не давал пассажирам третьего класса прохода наверх, поскольку не был проинформирован о серьёзности положения

--
Вычислить палубу пасажира на основе номера каюты

perform independence test of Pclass and Embarked
X-squared = 123.75, df = 4, p-value < 2.2e-16

check ticket info

A -> 1 (36)
B -> 1 (101)
C -> 1 (134)
D -> 1 (49),2 (39),3 (few)
E -> 1 ,2 (65),3 (few)
F -> 2 (64),3 (most)
G -> 3 (few)

infer deck from cabin number or class


handle interactions between Sex and title_clean, because Sex is (almost) useless when knowing passenger's title.

perform data cleanings as functions, not as scripts.

check and clean test data.


current situation #1:
  These are the variables that I engineered:
    cabin_multiple:
      Number of cabins occupied by a passenger. Can be viewed as proxy for a 
      socio-economic status. Considered insignificant in the logistic regression
      setting, likely due to a presence of Pclass variable,
      which is the main SE status indicator.
    
    cabin_deck:
      Indicator of the passengers deck location. Was created because there was 
      bias towards lower deck passengers, turned out to be uninformative,
      since a lot of passengers had unknown Cabin number, and therefore unknown
      cabin deck. Can be viewed as proxy for a 
      socio-economic status. Considered insignificant in the logistic regression
      setting, likely due to its low info value.
      
    family_size:
      Sum of Parch and SibSp columns, which means number of children/parents
      on board + number of siblings on board. Considered significant in the
      logistic regression setting. Its coefficient in the model has negative
      value, which suggests that passengers with bigger families had lower log-odds
      of survival. Should I explore it further?
      
    title:
      Passengers title (Mr., Miss., Mrs., etc.) extracted from name. Considered
      significant but not included in the logistic regression model, because of 
      rank defficiency. There are rare titles, like the Countess and Jonkheer,
      which include only one or two people, therefore considered not representative.
      title_clean is used instead of title.
      
    title_clean:
      Same as title, but rare titles aggregated to more common ones, like the Countess
      and Jonkheer become Noble. Considered significant and included into log. reg.
      model. The problem with clean titles is that titles like Mrs. and Mr. implie
      passengers sex, which allows to remove Sex from selected predictors, but
      titles like Noble and Professional don't implie sex. It means that in the 
      model without sex as predictor, those observations lose crucial sex information.
      title_clean_alt wes designed to solve this problem, but
      it didn't work. There are only 23 such observations in the training set,
      so I decided to include title_clean as it is. 
      

  I imputed missing ages with title_clean-based median ages.

  Here is the summary of cross-validated logistic regression fit:
    Generalized Linear Model 

    891 samples
      4 predictor
      2 classes: '0', '1' 

    No pre-processing
    Resampling: Cross-Validated (10 fold) 
    Summary of sample sizes: 803, 802, 801, 802, 802, 802, ... 
    Resampling results:

      Accuracy   Kappa    
      0.8270869  0.6310522


    > summary(model)

    Call:
    NULL

    Coefficients:
                            Estimate Std. Error z value Pr(>|z|)    
    (Intercept)              4.438242   0.586834   7.563 3.94e-14 ***
    Age                     -0.035989   0.009918  -3.629 0.000285 ***
    Pclass2                 -1.511099   0.295405  -5.115 3.13e-07 ***
    Pclass3                 -2.619664   0.278499  -9.406  < 2e-16 ***
    title_cleanMilitary     -2.682309   1.127774  -2.378 0.017387 *  
    title_cleanMiss.        -0.314314   0.477056  -0.659 0.509984    
    title_cleanMr.          -3.229963   0.522539  -6.181 6.36e-10 ***
    title_cleanMrs.          0.662545   0.545969   1.214 0.224930    
    title_cleanNoble        -2.337812   1.084746  -2.155 0.031149 *  
    title_cleanProfessional -3.113403   0.880316  -3.537 0.000405 ***
    family_size             -0.451958   0.079195  -5.707 1.15e-08 ***
    ---
    Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

    (Dispersion parameter for binomial family taken to be 1)

        Null deviance: 1186.66  on 890  degrees of freedom
    Residual deviance:  733.47  on 880  degrees of freedom
    AIC: 755.47

    Number of Fisher Scoring iterations: 5
    
  
  
  Here is the summary of alternative log. reg. fit with title_clean_alt:
    Generalized Linear Model 

    891 samples
      4 predictor
      2 classes: '0', '1' 

    No pre-processing
    Resampling: Cross-Validated (10 fold) 
    Summary of sample sizes: 803, 802, 801, 802, 802, 802, ... 
    Resampling results:

      Accuracy   Kappa    
      0.8338287  0.6454771


    > summary(model)

    Call:
    NULL

    Coefficients:
                                    Estimate Std. Error z value Pr(>|z|)    
    (Intercept)                     16.312680 502.529997   0.032 0.974104    
    Age                             -0.035675   0.009905  -3.602 0.000316 ***
    Pclass2                         -1.499655   0.293900  -5.103 3.35e-07 ***
    Pclass3                         -2.611272   0.278073  -9.391  < 2e-16 ***
    title_clean_altHighStatus_male -15.120127 502.530084  -0.030 0.975997    
    title_clean_altMaster.         -11.885109 502.530099  -0.024 0.981131    
    title_clean_altMiss.           -12.203120 502.529880  -0.024 0.980627    
    title_clean_altMr.             -15.120306 502.529823  -0.030 0.975997    
    title_clean_altMrs.            -11.231605 502.529901  -0.022 0.982169    
    family_size                     -0.451818   0.079306  -5.697 1.22e-08 ***
    ---
    Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

    (Dispersion parameter for binomial family taken to be 1)

        Null deviance: 1186.66  on 890  degrees of freedom
    Residual deviance:  728.78  on 881  degrees of freedom
    AIC: 748.78

    Number of Fisher Scoring iterations: 13

current situation #2:
  I've created family_type variable, which is just categorical family_size. Including it and its interactions
  with Pclass and Age into the model didn't improve the log. reg. model.
  I think it's time to move on with model selection and tuning.
  I've fitted LDA and got almost same results.
  
current situation #3:
  I've fit Random Forest, GBM and XGBoost to the data.All of the ensemble methods 
  performed better than linear ones. XGB seems to be the best model so far.
  Here the performance summary:
    # A tibble: 5 × 7
      .estimator model    accuracy  sens  spec precision f_meas
      <chr>      <chr>       <dbl> <dbl> <dbl>     <dbl>  <dbl>
    1 binary     logistic    0.824 0.880 0.734     0.841  0.860
    2 binary     lda         0.833 0.893 0.737     0.845  0.868
    3 binary     rf          0.845 0.905 0.749     0.852  0.878
    4 binary     gbm         0.853 0.913 0.757     0.858  0.884
    5 binary     xgb         0.861 0.911 0.781     0.870  0.890

current situation #4:
  I've decided to drop LDA and GBM. I don't seen any reason to keep them, since LDA perform almost the same as Log Reg, 
  but is more complex (I think), and GBM usually perform worse then XGB.
  XGB turned out to be unstable in its prediction accuracy. It's oscillating around 86%.
  It was about 88% once! I considered it suspicious so I refit it with different seed. RF sometimes outperforms it.
  I might need to play with tuning a little bit more, but I think I'm reached the ceiling of performance for these kind of models
  in the current setting. RF, unlike XGB,  shown consistency in prediciton accuracy, about 85.1% through different seeds.
  Current performance state:
    # A tibble: 3 × 7
      .estimator model       accuracy  sens  spec precision f_meas
      <chr>      <chr>          <dbl> <dbl> <dbl>     <dbl>  <dbl>
    1 binary     logistic       0.824 0.880 0.734     0.841  0.860
    2 binary     rf             0.851 0.913 0.751     0.855  0.883
    3 binary     xgb_stage_1    0.853 0.900 0.778     0.867  0.883

  xgb_stage_1 indicates that in this fit there was used coarse param grid, to find promising param regions.
  